{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7BeHe7Hk_SQ"
   },
   "source": [
    "# Семинар 8. Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzexosCsk_ST"
   },
   "source": [
    "![](https://drive.google.com/uc?id=13kmqLXa-3FBUJq0Q3XVOkz8TENpVTkqk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Jzd2sXfk_SU"
   },
   "source": [
    "*Source: https://www.upnxtblog.com/index.php/2017/12/06/17-machine-learning-algorithms-that-you-should-know/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzAr2Oejk_SV"
   },
   "source": [
    "Сами по себе решающие деревья используются в машинном обучении относительно редко, однако очень распространены методы, основанные на их композиции - ансамблях (Random Forest, XGBoost, LightGBM, CatBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJx5iz1qk_SW"
   },
   "source": [
    "## Линейные модели или решающие деревья?\n",
    "\n",
    "Можно ли сказать, что какой-то из этих двух типов моделей всегда лучше? Нет. В зависимости от пространственной структуры данных, один из них будет работать лучше:\n",
    "\n",
    "- Линейная модель, если данные хорошо линейно разделимы\n",
    "\n",
    "- Решающие деревья, если данные плохо линейно разделимы (присутствуют только кусочно-линейные или нелинейные зависимости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCZjbfGWk_SW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "WN7VGDk6k_Sc",
    "outputId": "7d21dd42-8de6-40b2-a07b-4f68ab456e4c"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "n = 500\n",
    "X = np.zeros(shape=(n, 2))\n",
    "X[:, 0] = np.linspace(-5, 5, 500)\n",
    "X[:, 1] = X[:, 0] + 0.5 * np.random.normal(size=n)\n",
    "y = (X[:, 1] > X[:, 0]).astype(int)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap=\"winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcrZmoKDk_Si"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "\n",
    "lr = LogisticRegression(random_state=13)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(f\"Linear model accuracy: {accuracy_score(y_pred_lr, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "5D8ZebbVk_Sp",
    "outputId": "ee25d35f-9ebc-4ce6-bdc6-f875f7e09735"
   },
   "outputs": [],
   "source": [
    "# !pip install mlxtend\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kXwTDCgk_Sr"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(f\"Decision tree accuracy: {accuracy_score(y_pred_dt, y_test):.2f}\")\n",
    "\n",
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "dt = CatBoostClassifier(random_state=13, verbose=False)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(f\"Catboost accuracy: {accuracy_score(y_pred_dt, y_test):.2f}\")\n",
    "\n",
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "4_ORHFUPk_Sy",
    "outputId": "24757b6c-42b4-4d6a-f22c-b1cc60440e03"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X = np.random.randn(500, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0).astype(int)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap=\"winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "emxtn3_Xk_S2",
    "outputId": "0af0a156-4dc8-45c7-a1af-0b9b999c477d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "\n",
    "lr = LogisticRegression(random_state=13)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(f\"Linear model accuracy: {accuracy_score(y_pred_lr, y_test):.2f}\")\n",
    "\n",
    "plot_decision_regions(X_test, y_test, lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZyvCcc5-k_S7",
    "outputId": "f4dbc9af-0441-470b-97d7-11462e8f4b9b"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(f\"Decision tree accuracy: {accuracy_score(y_pred_dt, y_test):.2f}\")\n",
    "\n",
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = CatBoostClassifier(random_state=13, verbose=False)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(f\"Catboost accuracy: {accuracy_score(y_pred_dt, y_test):.2f}\")\n",
    "\n",
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSgebfwWk_S_"
   },
   "source": [
    "## Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без регуляризации решающие деревья обладают фантастической способность к переобучению: можно построить решающее дерево, которое имеет нулевую ошибку на данной выборке, выделив для каждого объекта отдельный листик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "l3CDXRcmk_TA",
    "outputId": "05b1237f-7343-4cb4-ec2f-2cb510c32a63"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "n = 100\n",
    "X = np.random.normal(size=(n, 2))\n",
    "X[:50, :] += 0.25\n",
    "X[50:, :] -= 0.25\n",
    "y = np.array([1] * 50 + [0] * 50)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap=\"winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgBTDhINk_TC"
   },
   "source": [
    "Посмотрим, как влияют разные значения гиперпараметров решающего дерева на его структуру:\n",
    "\n",
    "- `max_depth`: максимальная глубина дерева\n",
    "- `min_samples_leaf`: минимальное число объектов в вершине дерева, необходимое для того, чтобы она могла быть листовой. Другими словами, когда мы будем перебирать пороги для разбиения в конкретной вершине, мы будем рассматривать только такие пороги, после разбиения по которым каждая из двух новых вершин будет содержать не менее `min_samples_leaf` объектов.\n",
    "- `min_samples_split`: минимальное число объектов во внутреннем узле, при котором мы будем делать разбиение этого листа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "colab_type": "code",
    "id": "bFdroxCGk_TD",
    "outputId": "c8fccf0c-f434-442e-c644-810c008e75b3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "\n",
    "for i, max_depth in enumerate([3, 5, None]):\n",
    "    for j, min_samples_leaf in enumerate([15, 5, 1]):\n",
    "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "        dt.fit(X, y)\n",
    "        ax[i][j].set_title(\"max_depth = {} | min_samples_leaf = {}\".format(max_depth, min_samples_leaf))\n",
    "        ax[i][j].axis(\"off\")\n",
    "        plot_decision_regions(X, y, dt, ax=ax[i][j])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDSA2oeDk_TF"
   },
   "source": [
    "На любой выборке (исключая те, где есть объекты с одинаковыми значениями признаков, но разными ответами) можно получить нулевую ошибку - с помощью максимально переобученного дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "hdlvbWRik_TF",
    "outputId": "cb8e50bf-4677-417e-e307-38ca032fb6e8"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=13)\n",
    "dt.fit(X, y)\n",
    "\n",
    "print(f\"Decision tree accuracy: {accuracy_score(y, dt.predict(X)):.2f}\")\n",
    "\n",
    "plot_decision_regions(X, y, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvmfSXRak_TJ"
   },
   "source": [
    "## Неустойчивость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATJDz_KMk_TK"
   },
   "source": [
    "Посмотрим, как будет меняться структура дерева без регуляризации, если брать для обучения разные 90%-ые подвыборки исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "colab_type": "code",
    "id": "BFYd1Rauk_TL",
    "outputId": "a1aa316a-6aaf-4bb1-bad1-b1a2433cec3f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        seed_idx = 3 * i + j\n",
    "        np.random.seed(seed_idx)\n",
    "        dt = DecisionTreeClassifier(random_state=13)\n",
    "        idx_part = np.random.choice(len(X), replace=False, size=int(0.9 * len(X)))\n",
    "        X_part, y_part = X[idx_part, :], y[idx_part]\n",
    "        dt.fit(X_part, y_part)\n",
    "        ax[i][j].set_title(\"sample #{}\".format(seed_idx))\n",
    "        ax[i][j].axis(\"off\")\n",
    "        plot_decision_regions(X_part, y_part, dt, ax=ax[i][j])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UF027SV0k_TO"
   },
   "source": [
    "## Решающее дерево из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjRVwIE7k_TP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6pFOIRRk_TR"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sP1O60SZk_TZ",
    "outputId": "122d2f58-c34f-49f7-9587-b41711374a1a"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "y = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "4sjlJ_U_k_Th",
    "outputId": "1a96a507-7ef1-4bc4-aea0-e0601fb96536"
   },
   "outputs": [],
   "source": [
    "plt.title(\"House price distribution\")\n",
    "plt.xlabel(\"price\")\n",
    "plt.ylabel(\"# samples\")\n",
    "plt.hist(y, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aIfOQbH3k_Tk",
    "outputId": "b77988f2-f0b3-4af3-e133-d60ae87d3a63"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "3YbPFyUyk_T9",
    "outputId": "4dcb9845-eff3-41a5-d2a0-aef6593ec47e"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=3, random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "plot_tree(dt, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "v8ou_FlUmcBu",
    "outputId": "3dc58d3d-7af9-4d06-c495-da08090abc27"
   },
   "outputs": [],
   "source": [
    "max_depth_array = range(2, 20)\n",
    "mse_array = []\n",
    "\n",
    "for max_depth in max_depth_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "\n",
    "plt.plot(max_depth_array, mse_array)\n",
    "plt.title(\"Dependence of MSE on max depth\")\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "GQKZpyxsmysH",
    "outputId": "e1d47d5d-01fe-453c-b316-93efd6e9c681"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"max_depth\": max_depth_array,\n",
    "    \"MSE\": mse_array\n",
    "}).sort_values(by=\"MSE\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "eJKzzKpcnI4-",
    "outputId": "11fb50a0-0292-41c2-b79c-fa1bc0e26ed8"
   },
   "outputs": [],
   "source": [
    "min_samples_leaf_array = range(1, 20)\n",
    "mse_array = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=6, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "    \n",
    "plt.plot(min_samples_leaf_array, mse_array)\n",
    "plt.title(\"Dependence of MSE on min samples leaf\")\n",
    "plt.xlabel(\"min samples leaf\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"min_samples_leaf\": min_samples_leaf_array,\n",
    "    \"MSE\": mse_array\n",
    "}).sort_values(by=\"MSE\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "J7_8aCDknl7u",
    "outputId": "f4e35722-4904-4e14-9b0f-4b4054eb7e11"
   },
   "outputs": [],
   "source": [
    "min_samples_split_array = range(2, 20)\n",
    "mse_array = []\n",
    "\n",
    "for min_samples_split in min_samples_split_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=6, min_samples_leaf=1, min_samples_split=min_samples_split, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "\n",
    "plt.plot(min_samples_split_array, mse_array)\n",
    "plt.title(\"Dependence of MSE on min samples split\")\n",
    "plt.xlabel(\"min samples split\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"min_samples_split\": min_samples_split_array,\n",
    "    \"MSE\": mse_array\n",
    "}).sort_values(by=\"MSE\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(DecisionTreeRegressor(random_state=13),\n",
    "                  param_grid={\n",
    "                     # 'max_features': ['auto', 'log2', 'sqrt'],\n",
    "                      'max_depth': range(2, 20),\n",
    "                      'min_samples_leaf': range(1, 20)\n",
    "                  },\n",
    "                  cv=5,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "OPAgS05sk_UC",
    "outputId": "63e4b3b5-1ac2-43f5-df86-57fe06639a19"
   },
   "outputs": [],
   "source": [
    "dt_our_best = DecisionTreeRegressor(max_depth=6, random_state=13)\n",
    "dt_our_best.fit(X_train, y_train)\n",
    "print(mean_squared_error(y_test, dt_our_best.predict(X_test)))\n",
    "\n",
    "plot_tree(dt_our_best, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gs_best = DecisionTreeRegressor(max_depth=11,  min_samples_leaf=3, random_state=13)\n",
    "dt_gs_best.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, dt_gs_best.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "9GtCb9qgk_UH",
    "outputId": "432aad6f-ea04-4a6e-b3ed-d35f5e50735b"
   },
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": dt.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_importances['feature'], df_importances['importance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exMPZsN_k_UJ"
   },
   "source": [
    "Влияет ли стандартизация (масштабирование) признаков на результат работы решающего дерева?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fA9sNUrNk_UL",
    "outputId": "279f45e8-4861-494b-f5e0-6ea2682ad064"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(sc.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "q_nS3aRgk_UM",
    "outputId": "0f06d0af-91ff-4bc6-d3bb-4df247d0b08d"
   },
   "outputs": [],
   "source": [
    "print(\"No scaling is applied\\n\")\n",
    "\n",
    "for max_depth in [3, 6]:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    print(f\"MSE on test set for depth {max_depth}: {mean_squared_error(y_test, dt.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C7OkLotck_UN",
    "outputId": "a4fecdab-ff8f-484b-d3e7-ff7bbc2b9889"
   },
   "outputs": [],
   "source": [
    "print(\"Standard scaling is applied\\n\")\n",
    "\n",
    "for max_depth in [3, 6]:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train_scaled, y_train)\n",
    "    print(f\"MSE on test set for depth {max_depth}: {mean_squared_error(y_test, dt.predict(X_test_scaled)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скетч решающего дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Критерий ошибки:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) + \\frac{|R_r|}{|R_m|}H(R_r) \\to \\min_{j, t}\n",
    "$$\n",
    "\n",
    "$R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "$H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(data=boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "X[\"target\"] = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1**: реализуйте подсчет критерия ошибки. Для этого реализуйте функции для подсчета значения критерия информативности, а также для разбиения вершины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "def H(R: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Compute impurity criterion for a fixed set of objects R.\n",
    "    Last column is assumed to contain target value\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def split_node(R_m: np.array, feature: str, t: float) -> Iterable[np.array]:\n",
    "    \"\"\"\n",
    "    Split a fixed set of objects R_m given feature number and threshold t\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def q_error(R_m: np.array, feature: str, t: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute error criterion for given split parameters\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2**: переберите все возможные разбиения выборки по одному из признаков и постройте график критерия ошибки в зависимости от значения порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"<choose feature>\"\n",
    "Q_array = []\n",
    "\n",
    "feature_values = np.unique(X_train[feature])\n",
    "for t in feature_values:\n",
    "    Q_array.append(q_error(X_train, feature, t))\n",
    "\n",
    "plt.plot(feature_values, Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Q error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**: Напишите функцию, находящую оптимальное разбиение данной вершины по данному признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m: np.array, feature: str) -> Tuple[float, List[float]]:\n",
    "    Q_array = []\n",
    "    feature_values = np.unique(R_m[feature])\n",
    "    \n",
    "    for t in feature_values:\n",
    "        Q_array.append(q_error(R_m, feature, t))\n",
    "        \n",
    "    opt_threshold = # your code here\n",
    "    \n",
    "    return opt_threshold, Q_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, Q_array = get_optimal_split(X_train, feature)\n",
    "plt.plot(np.unique(X_train[feature]), Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Q error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4**: Для первого разбиения найдите признак, показывающий наилучшее качество. Каков порог разбиения и значение качества? Постройте график критерия ошибки для данного признака в зависимости от значения порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for f in X_train.columns:\n",
    "    t, Q_array = get_optimal_split(X_train, f)\n",
    "    min_error = min(Q_array)\n",
    "    results.append((f, t, min_error))\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature: {} | optimal t: {} | min Q error: {:.2f}\".format(f, t, min_error))\n",
    "    plt.plot(np.unique(X_train[f]), Q_array)\n",
    "    plt.show()\n",
    "    \n",
    "results = sorted(results, key=lambda x: x[2])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=[\"feature\", \"optimal t\", \"min Q error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_feature, optimal_t, optimal_error = # optimal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Задание 5**: Изобразите разбиение визуально. Для этого постройте диаграмму рассеяния целевой переменной в зависимости от значения найденного признака. Далее изобразите вертикальную линию, соответствующую порогу разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[optimal_feature], y)\n",
    "plt.axvline(x=optimal_t, color=\"red\")\n",
    "plt.xlabel(optimal_feature)\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Feature: {} | optimal t: {} | Q error: {:.2f}\".format(optimal_feature, optimal_t, optimal_error))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sem_trees_solved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
